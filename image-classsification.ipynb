{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"4bfdd509-415b-45de-9242-859a37d50c1c","_cell_guid":"d1354728-097d-45d3-9ce4-f848c6229872","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rename_files(folder):\n    for root, _, files in os.walk(folder):\n        for filename in files:\n            if \" \" in filename:\n                old_path = os.path.join(root, filename)\n                new_filename = filename.replace(\" \", \"_\")\n                new_path = os.path.join(root, new_filename)\n                \n                # Check if the new file name already exists, and if so, remove it\n                if os.path.exists(new_path):\n                    os.remove(new_path)\n                \n                # Rename the file\n                os.rename(old_path, new_path)\n\nrename_files(\"/kaggle/input\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import h5py\nfrom PIL import Image, ImageOps, ImageEnhance\n\ndef adjust_contrast(img, contrast_factor):\n    enhancer = ImageEnhance.Contrast(img)\n    contrast_adjusted_img = enhancer.enhance(contrast_factor)\n    return Image.blend(img, contrast_adjusted_img, contrast_factor)\n\n# Function to read and convert a PNG file to a dataset\ndef convert_jpg_to_array(image_path):\n    image = Image.open(image_path)\n    image = adjust_contrast(image, 1.5)\n    image_data = np.array(image)\n    return image_data\n    \ndef convert_images_to_dataset():\n    ls = []\n    image_data=[]\n    for root, _, files in os.walk(\"/kaggle/input/\"):\n        label = root[len(\"/kaggle/input/rice-leaf-images/rice_images\")+1:]\n        for filename in files:\n            image_path = os.path.join(root, filename)\n            data = convert_jpg_to_array(image_path)\n            image_data.append(data)\n            if label == \"_BrownSpot\":\n                ls.append(1)\n            elif label == \"_Healthy\":\n                ls.append(0)\n            elif label == \"_Hispa\":\n                ls.append(2)\n            elif label == \"_LeafBlast\":\n                ls.append(3)\n    return image_data, ls\n\nimage_data, ls = convert_images_to_dataset()","metadata":{"_uuid":"dd126ae7-dc90-4635-8f02-8a3979bf438b","_cell_guid":"c6c5050a-55a3-4dbc-bf8e-d5ea74071d8f","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame()\ndf[\"image_data\"] = image_data\ndf[\"label\"] = ls\ndf = df.sample(frac=1, random_state=42)  # Set a random_state for reproducibility\ndf.reset_index(drop=True, inplace=True)\nimage_data = df[\"image_data\"].to_list()\nlabel = df[\"label\"].to_list()\nh5_file_path = 'train_rice_data.h5'  \nwith h5py.File(h5_file_path, 'w') as hf:\n    hf.create_dataset('image_data', data=np.array(image_data))\n    hf.create_dataset('label', data=np.array(label))\n    ","metadata":{"execution":{"iopub.status.busy":"2023-09-11T10:02:59.556739Z","iopub.status.idle":"2023-09-11T10:02:59.557432Z","shell.execute_reply.started":"2023-09-11T10:02:59.557113Z","shell.execute_reply":"2023-09-11T10:02:59.557144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cutoff = int(len(df) * 0.8)\nimage_data = df[\"image_data\"].iloc[cutoff:].to_list()\nlabel = df[\"label\"].iloc[cutoff:].to_list()\nh5_file_path = 'test_rice_data.h5'  \nwith h5py.File(h5_file_path, 'w') as hf:\n    hf.create_dataset('image_data', data=np.array(image_data))\n    hf.create_dataset('label', data=np.array(label))","metadata":{"execution":{"iopub.status.busy":"2023-09-11T10:02:59.559431Z","iopub.status.idle":"2023-09-11T10:02:59.560004Z","shell.execute_reply.started":"2023-09-11T10:02:59.559726Z","shell.execute_reply":"2023-09-11T10:02:59.559753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}